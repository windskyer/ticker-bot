import time
import random
from datetime import datetime
import google.generativeai as genai
from config import cfg

API_KEY = cfg["gemini"]["key"]

# === Gemini API Key é…ç½® ===
genai.configure(api_key=API_KEY)


def safe_extract(response):
    """ä» Gemini response é‡Œå®‰å…¨æå–æ–‡æœ¬"""
    if not hasattr(response, "candidates") or not response.candidates:
        return None
    texts = []
    for c in response.candidates:
        if getattr(c, "content", None) and c.content.parts:
            for p in c.content.parts:
                t = getattr(p, "text", None)
                if t and t.strip():
                    texts.append(t.strip())
    return "\n".join(texts) if texts else None


MODEL_CANDIDATES = [
    "models/gemini-2.5-pro",
    "models/gemini-1.5-pro",
    "models/gemini-1.5-flash"
]


def call_gemini_with_retry(prompt, hard_timeout_s=300, per_call_timeout_s=30,
                           max_backoff_s=64, temperature=0.7, max_output_tokens=900, debug=False):
    start = time.time()
    attempt = 0
    last_exc = None
    model_idx = 0

    while time.time() - start < hard_timeout_s:
        attempt += 1
        model_name = MODEL_CANDIDATES[model_idx % len(MODEL_CANDIDATES)]
        model_idx += 1
        if debug:
            print(f"ğŸ”„ å°è¯• #{attempt}ï¼Œæ¨¡å‹ï¼š{model_name}")

        try:
            model = genai.GenerativeModel(
                model_name,
                generation_config={"temperature": temperature, "max_output_tokens": max_output_tokens}
            )
            resp = model.generate_content(prompt, request_options={"timeout": per_call_timeout_s})
            text = safe_extract(resp)
            if text:
                return text
        except Exception as e:
            last_exc = e
            if debug:
                print(f"âŒ è°ƒç”¨å¼‚å¸¸ï¼š{e}")

        sleep_s = min(max_backoff_s, 2 ** min(attempt, 6)) + random.uniform(0, 1.0)
        if debug:
            print(f"â³ ç­‰å¾… {sleep_s:.1f}s åé‡è¯•...")
        time.sleep(sleep_s)

    msg = "âš ï¸ ç”Ÿæˆå¤±è´¥ï¼šå¤šæ¨¡å‹å¤šæ¬¡é‡è¯•åä»æ— å†…å®¹ã€‚"
    if last_exc and debug:
        msg += f"\næœ€åé”™è¯¯ï¼š{last_exc}"
    return msg


# ================= Gemini AI æ—¥æŠ¥ =================
def generate_report(stock_data, debug=False):
    today = datetime.now().strftime("%Y-%m-%d")
    prompt = f"""
ä»Šå¤©æ˜¯ {today}ã€‚ä»¥ä¸‹æ˜¯æœ€æ–°çš„æ”¶ç›˜ä»·ï¼ˆå·²ç²¾ç®€ï¼‰ï¼š
{stock_data}

è¯·ç”Ÿæˆä¸€ä»½ç®€çŸ­çš„é‡‘èæ—¥æŠ¥ï¼ŒåŒ…å«ï¼š
1) å¸‚åœºæ•´ä½“è¶‹åŠ¿
2) æ¯åªè‚¡ç¥¨çš„ç®€è¦ç‚¹è¯„ï¼ˆå¯åˆç†æ¨æµ‹é©±åŠ¨å› ç´ ï¼‰
3) æœªæ¥é£é™©æˆ–æœºä¼šæç¤º
è¦æ±‚ï¼šä¸­æ–‡ã€ä¸“ä¸šã€ç²¾ç‚¼ã€‚è‹¥ä¿¡æ¯ä¸è¶³ï¼Œè¯·è¿”å›â€œä»Šæ—¥æš‚æ— æ•°æ®â€ã€‚
"""
    return call_gemini_with_retry(prompt, debug=debug)


def generate_report_macro(data, debug=False):
    today = datetime.now().strftime("%Y-%m-%d")
    latest = data.tail(1).iloc[0].to_dict()
    prompt = f"""
ä»Šå¤©æ˜¯ {today}ã€‚ä»¥ä¸‹æ˜¯æœ€æ–°çš„å®è§‚èµ„äº§æ”¶ç›˜ä»·ï¼š
{latest}

è¯·ç”¨ä¸­æ–‡å†™ä¸€ä»½ç®€çŸ­çš„é‡‘èæ—¥æŠ¥ï¼Œæ€»ç»“ï¼š
1. å®è§‚å¸‚åœºæ•´ä½“è¶‹åŠ¿
2. å››ç±»èµ„äº§çš„è¡¨ç°å’Œç®€è¦ç‚¹è¯„
3. é£é™©æˆ–æœºä¼šæç¤º
è¦æ±‚ä¸“ä¸šç®€æ´ã€‚
"""
    return call_gemini_with_retry(prompt, debug=debug)
